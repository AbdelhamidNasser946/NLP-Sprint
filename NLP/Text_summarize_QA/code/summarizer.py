from transformers import pipeline


def load_summarizer_model():
    return pipeline("summarization", model="facebook/bart-large-cnn")


def summarize_text(summarizer, text, max_length=180, min_length=50, do_sample=False):
    summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=do_sample)
    return summary[0]['summary_text']


if __name__ == "__main__":
    article = """What is Text Summarization?

    Text summarization is the process of condensing a large text document into a shorter version while preserving its key 
    information and meaning. The goal of text summarization is to extract the most important information from a text 
    document and present it in a concise and comprehensible form. This can be done through techniques such as keyword 
    extraction, sentence extraction, or abstractive summarization. Text summarization has various applications including 
    news aggregation, content analysis, and information retrieval. How text summarization performed using Transformers?
    
    Text summarization using Transformers can be performed in two ways: extractive summarization and abstractive 
    summarization.

    Extractive summarization: In this approach, the most important sentences or phrases from the original text are 
    selected and combined to form a summary. This can be done using algorithms such as TextRank, which uses 
    graph-based algorithms to rank sentences based on their relevance and importance. Transformers can be used to 
    process the text, extract features, and perform sentence ranking. Abstractive summarization: In this approach, 
    a new summary is generated by understanding the context of the original text and generating new phrases and 
    sentences that summarize its content. This can be done using techniques such as encoder-decoder models, 
    where the encoder processes the input text to extract its features and the decoder generates the summary. 
    Transformers can be used as the encoder or decoder in this architecture.

    In both extractive and abstractive summarization, Transformers can be trained on large amounts of text data to learn 
    the patterns and relationships between words, sentences, and documents, making them well-suited for text 
    summarization tasks."""

    summ_model = load_summarizer_model()
    print(summarize_text(summ_model, article))
